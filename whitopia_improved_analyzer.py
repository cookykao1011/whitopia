#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Whitopia.jp åº—é‹ªé–‹æ¥­ä¿¡æ¯åˆ†æå™¨ (æ”¹é€²ç‰ˆ)
æ›´å¥½åœ°åˆ†æå’Œæ•´ç†åº—é‹ªé–‹æ¥­çš„è©³ç´°ä¿¡æ¯
"""

import json
import re
from datetime import datetime

class ImprovedWhitopiaAnalyzer:
    def __init__(self, json_file='whitopia_news.json'):
        self.json_file = json_file
        self.store_openings = []
    
    def load_data(self):
        """è¼‰å…¥JSONæ•¸æ“š"""
        try:
            with open(self.json_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {self.json_file}")
            return None
        except json.JSONDecodeError:
            print(f"JSONæ ¼å¼éŒ¯èª¤: {self.json_file}")
            return None
    
    def extract_store_info(self, text):
        """å¾æ–‡å­—ä¸­æå–åº—é‹ªä¿¡æ¯"""
        store_info = {
            'store_name': '',
            'prefecture': '',
            'date': '',
            'full_text': text
        }
        
        # æ¸…ç†æ–‡å­—ï¼Œç§»é™¤å¤šé¤˜çš„ç©ºç™½å’Œæ›è¡Œ
        clean_text = re.sub(r'\s+', '', text)
        
        # æå–åº—é‹ªåç¨± - æ›´ç²¾ç¢ºçš„æ¨¡å¼
        store_name_patterns = [
            r'ã€Œ(ãƒ›ãƒ¯ã‚¤ãƒˆãƒ”ã‚¢[^ã€]+åº—)ã€',
            r'(ãƒ›ãƒ¯ã‚¤ãƒˆãƒ”ã‚¢[^ãŒ]+åº—)ãŒ',
            r'(ãƒ›ãƒ¯ã‚¤ãƒˆãƒ”ã‚¢[^ï¼]+åº—)ï¼',
            r'(ãƒ›ãƒ¯ã‚¤ãƒˆãƒ”ã‚¢\w+åº—)'
        ]
        
        for pattern in store_name_patterns:
            match = re.search(pattern, clean_text)
            if match:
                store_info['store_name'] = match.group(1)
                break
        
        # æå–éƒ½é“åºœç¸£ä¿¡æ¯ - æ›´ç²¾ç¢ºçš„æ¨¡å¼
        prefecture_patterns = [
            r'æ–°ãŸã«([^çœŒ]+çœŒ)ã«',
            r'([^çœŒ]+çœŒ)ã«OPEN',
            r'ãŒæ–°ãŸã«([^çœŒ]+çœŒ)',
            r'ã€Œ[^ã€]+ã€ãŒæ–°ãŸã«([^çœŒ]+çœŒ)'
        ]
        
        for pattern in prefecture_patterns:
            match = re.search(pattern, clean_text)
            if match:
                store_info['prefecture'] = match.group(1)
                break
        
        # æå–æ—¥æœŸ
        date_patterns = [
            r'(\d{4}-\d{2}-\d{2})',
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',
            r'(\d{4})/(\d{1,2})/(\d{1,2})'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                if len(match.groups()) == 1:
                    store_info['date'] = match.group(1)
                else:
                    year, month, day = match.groups()
                    store_info['date'] = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                break
        
        return store_info
    
    def analyze_store_openings(self):
        """åˆ†æåº—é‹ªé–‹æ¥­ä¿¡æ¯"""
        data = self.load_data()
        if not data:
            return
        
        print("=" * 70)
        print("ğŸª Whitopia.jp åº—é‹ªé–‹æ¥­ä¿¡æ¯è©³ç´°åˆ†æ")
        print("=" * 70)
        print(f"ğŸ“Š åˆ†ææ™‚é–“: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        print(f"ğŸ“… æ•¸æ“šæŠ“å–æ™‚é–“: {data.get('scrape_time', 'æœªçŸ¥')}")
        print(f"ğŸ“ˆ ç¸½å…±æ‰¾åˆ°é …ç›®: {data.get('total_items', 0)} å€‹")
        print(f"ğŸ¬ åº—é‹ªç›¸é—œé …ç›®: {data.get('store_related_items', 0)} å€‹")
        print()
        
        store_openings = []
        
        for item in data.get('store_news', []):
            full_text = item.get('content', '') + ' ' + item.get('title', '')
            store_info = self.extract_store_info(full_text)
            
            # å¦‚æœæ²’æœ‰å¾å…§å®¹ä¸­æå–åˆ°æ—¥æœŸï¼Œä½¿ç”¨é …ç›®çš„æ—¥æœŸ
            if not store_info['date'] and item.get('date'):
                store_info['date'] = item['date']
            
            store_info['match_keyword'] = item.get('match_keyword', '')
            store_info['url'] = item.get('url', '')
            
            store_openings.append(store_info)
        
        # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        store_openings.sort(key=lambda x: x['date'] if x['date'] else '0000-00-00', reverse=True)
        
        print("ğŸ—“ï¸ åº—é‹ªé–‹æ¥­æ™‚é–“è¡¨:")
        print("=" * 70)
        
        for i, store in enumerate(store_openings, 1):
            if store['date']:
                try:
                    date_obj = datetime.strptime(store['date'], '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%Yå¹´%mæœˆ%dæ—¥')
                    weekday = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][date_obj.weekday()]
                    date_display = f"{formatted_date} ({weekday})"
                except:
                    date_display = store['date']
            else:
                date_display = "æ—¥æœŸæœªçŸ¥"
            
            print(f"ğŸª {i}. {store['store_name'] or 'åº—åæœªçŸ¥'}")
            print(f"   ğŸ“… é–‹æ¥­æ—¥æœŸ: {date_display}")
            print(f"   ğŸ“ æ‰€åœ¨åœ°å€: {store['prefecture'] or 'åœ°å€æœªçŸ¥'}")
            print(f"   ğŸ” é—œéµè©: {store['match_keyword']}")
            print(f"   ğŸ”— URL: {store['url']}")
            
            # é¡¯ç¤ºåŸå§‹æ–‡å­—çš„é—œéµéƒ¨åˆ†
            key_text = store['full_text'][:150].replace('\n', ' ')
            print(f"   ğŸ“ å…§å®¹æ‘˜è¦: {key_text}...")
            print("-" * 70)
        
        # çµ±è¨ˆåˆ†æ
        print("\nğŸ“Š çµ±è¨ˆåˆ†æ:")
        print("=" * 70)
        
        # æŒ‰æœˆä»½çµ±è¨ˆ
        monthly_stats = {}
        prefecture_stats = {}
        
        for store in store_openings:
            if store['date']:
                try:
                    month = store['date'][:7]  # YYYY-MM
                    monthly_stats[month] = monthly_stats.get(month, 0) + 1
                except:
                    pass
            
            if store['prefecture']:
                prefecture_stats[store['prefecture']] = prefecture_stats.get(store['prefecture'], 0) + 1
        
        print("ğŸ“… æŒ‰æœˆä»½çµ±è¨ˆ:")
        for month, count in sorted(monthly_stats.items(), reverse=True):
            try:
                month_obj = datetime.strptime(month + '-01', '%Y-%m-%d')
                month_display = month_obj.strftime('%Yå¹´%mæœˆ')
                print(f"   {month_display}: {count} å®¶åº—é‹ª")
            except:
                print(f"   {month}: {count} å®¶åº—é‹ª")
        
        print("\nğŸ“ æŒ‰åœ°å€çµ±è¨ˆ:")
        for prefecture, count in sorted(prefecture_stats.items(), key=lambda x: x[1], reverse=True):
            print(f"   {prefecture}: {count} å®¶åº—é‹ª")
        
        # ç”Ÿæˆæ‘˜è¦å ±å‘Š
        print(f"\nğŸ“‹ æ‘˜è¦å ±å‘Š:")
        print("=" * 70)
        total_stores = len([s for s in store_openings if s['store_name']])
        print(f"âœ… æˆåŠŸè­˜åˆ¥åº—é‹ªæ•¸é‡: {total_stores} å®¶")
        print(f"ğŸ“ æ¶‰åŠåœ°å€æ•¸é‡: {len(prefecture_stats)} å€‹éƒ½é“åºœç¸£")
        print(f"ğŸ“… é–‹æ¥­æ™‚é–“è·¨åº¦: {min(monthly_stats.keys()) if monthly_stats else 'æœªçŸ¥'} è‡³ {max(monthly_stats.keys()) if monthly_stats else 'æœªçŸ¥'}")
        
        # ä¿å­˜è©³ç´°åˆ†æçµæœ
        analysis_result = {
            'analysis_time': datetime.now().isoformat(),
            'total_stores': total_stores,
            'store_openings': store_openings,
            'monthly_stats': monthly_stats,
            'prefecture_stats': prefecture_stats,
            'summary': {
                'total_identified_stores': total_stores,
                'prefectures_count': len(prefecture_stats),
                'date_range': {
                    'start': min(monthly_stats.keys()) if monthly_stats else None,
                    'end': max(monthly_stats.keys()) if monthly_stats else None
                }
            }
        }
        
        with open('whitopia_detailed_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°åˆ†æçµæœå·²ä¿å­˜åˆ° whitopia_detailed_analysis.json")
        
        return analysis_result

if __name__ == "__main__":
    analyzer = ImprovedWhitopiaAnalyzer()
    analyzer.analyze_store_openings()